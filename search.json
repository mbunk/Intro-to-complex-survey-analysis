[
  {
    "objectID": "part2/part_2-2.html",
    "href": "part2/part_2-2.html",
    "title": "2.2: Extensions",
    "section": "",
    "text": "The is the final session of the workshop and covers a few extensions, including regression diagnostics."
  },
  {
    "objectID": "part2/part_2-2.html#load-packages",
    "href": "part2/part_2-2.html#load-packages",
    "title": "2.2: Extensions",
    "section": "Load packages",
    "text": "Load packages\nLoad all of the required packages if they are not already in your R environment."
  },
  {
    "objectID": "part2/part_2-2.html#load-data",
    "href": "part2/part_2-2.html#load-data",
    "title": "2.2: Extensions",
    "section": "Load data",
    "text": "Load data\nRemember that we “saved” our wrangled dataset to the working directory in the previous section as an .RDatafile in our workshop folder.\n\n\nCode\nroot &lt;- \"C://Users//s1769862//OneDrive - University of Edinburgh//SLTF-workshop-August2024//\" # change with where the folder lies in your filepath\ness9 &lt;- readRDS(file= file.path(root, \"Data\", \"ess9.RData\"))\n\n\nWe also need to re-specify our sampling design object and PSU adjustment settings.\n\n\nCode\ndesign2 &lt;- survey::svydesign(ids = ~psu, strata = ~stratum, weights = ~anweight, data = ess9)\noptions(survey.lonely.psu=\"adjust\") # adjust for lonely psu"
  },
  {
    "objectID": "part2/part_2-2.html#model-fit",
    "href": "part2/part_2-2.html#model-fit",
    "title": "2.2: Extensions",
    "section": "Model fit",
    "text": "Model fit\nFirst, we can expand upon the reporting of regression outputs by integrating model fit criteria into the summary tables.\nThis can be accomplished via glance table from the gtsummary tbl_regression function, which pulls the fit information directly from the svyglm model output.\n\n\nCode\nsurvey::svyglm(nwspol ~ age, family=gaussian, design=design2) %&gt;%\n  tbl_regression() %&gt;%\n  bold_p(t=0.05) %&gt;%\n  add_glance_table(include=c(everything()))\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    age\n\n\n\n        18 to 25\n—\n—\n\n        25 to 35\n5.1\n-5.8, 16\n0.4\n        36 to 49\n3.9\n-6.0, 14\n0.4\n        50 to 64\n17\n6.5, 28\n0.002\n        65+\n39\n30, 49\n&lt;0.001\n    Null deviance\n1,315,576,458\n\n\n    Null df\n47,593\n\n\n    AIC\n614,789\n\n\n    BIC\n1,305,684,998\n\n\n    Deviance\n1,305,684,944\n\n\n    Residual df\n21,255\n\n\n    No. Obs.\n47,594\n\n\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nThis also applied to logistic regression results\n\n\nCode\nsurvey::svyglm(vote ~ trstprl + gender + age, family=quasibinomial, design = design2) %&gt;% tbl_regression(exponentiate=T, label = c(trstprl~\"Trust in parliament\")) %&gt;%\n  bold_p(t=0.05) %&gt;%\n  add_glance_table(include=c(everything()))\n\n\n\n\n\n\n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    Trust in parliament\n1.17\n1.15, 1.19\n&lt;0.001\n    gender\n\n\n\n        Female\n—\n—\n\n        Male\n1.04\n0.96, 1.12\n0.4\n    age\n\n\n\n        18 to 25\n—\n—\n\n        25 to 35\n1.43\n1.24, 1.66\n&lt;0.001\n        36 to 49\n2.06\n1.79, 2.37\n&lt;0.001\n        50 to 64\n3.01\n2.61, 3.47\n&lt;0.001\n        65+\n3.41\n2.95, 3.94\n&lt;0.001\n    Null deviance\n44,668\n\n\n    Null df\n44,077\n\n\n    AIC\n42,547\n\n\n    BIC\n42,587\n\n\n    Deviance\n42,512\n\n\n    Residual df\n19,811\n\n\n    No. Obs.\n44,078\n\n\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\nPseudo r-squared\nThe automatic summary output does not include a pseudo r-squared estimate, but we can request this manually from the survey package.\n\n\nCode\nm1 &lt;- survey::svyglm(vote ~ trstprl + gender + age, family=quasibinomial, design = design2)\npsrsq(m1)\n\n\n[1] 0.04923396\n\n\nWe can add this information back to our the summary object created for the model.\n\n\nCode\nm1$r.squared &lt;- psrsq(m1)\n\nm1 %&gt;% tbl_regression(exponential=T,label = c(trstprl~\"Trust in parliament\")) %&gt;%\n  bold_p(t=0.05) %&gt;%\n  add_glance_table(include=c(everything()))\n\n\n\n\n\n\n  \n    \n      Characteristic\n      log(OR)1\n      95% CI1\n      p-value\n    \n  \n  \n    Trust in parliament\n0.16\n0.14, 0.17\n&lt;0.001\n    gender\n\n\n\n        Female\n—\n—\n\n        Male\n0.04\n-0.04, 0.11\n0.4\n    age\n\n\n\n        18 to 25\n—\n—\n\n        25 to 35\n0.36\n0.21, 0.51\n&lt;0.001\n        36 to 49\n0.72\n0.58, 0.86\n&lt;0.001\n        50 to 64\n1.1\n0.96, 1.2\n&lt;0.001\n        65+\n1.2\n1.1, 1.4\n&lt;0.001\n    Null deviance\n44,668\n\n\n    Null df\n44,077\n\n\n    AIC\n42,547\n\n\n    BIC\n42,587\n\n\n    Deviance\n42,512\n\n\n    Residual df\n19,811\n\n\n    No. Obs.\n44,078\n\n\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can select which estimation methods to use! See the full list on the data documentation methods = c(\"Nagelkerke\", \"Cox-Snell\")"
  },
  {
    "objectID": "part2/part_2-2.html#task-9",
    "href": "part2/part_2-2.html#task-9",
    "title": "2.2: Extensions",
    "section": "Task 9",
    "text": "Task 9\nAdd model fit information to your own regression model.\n\nCustomise the output information and styling!\nFor reference, see tbl_regression\n\n\n\nCode\n## Write your own code!"
  },
  {
    "objectID": "part2/part_2-2.html#plotting-model-coefficients",
    "href": "part2/part_2-2.html#plotting-model-coefficients",
    "title": "2.2: Extensions",
    "section": "Plotting model coefficients",
    "text": "Plotting model coefficients\nModel coefficients from survey adjusted models can also be plotted.\nI like using the jtools package for visualising the odds rations from binary logistic regression models.\n\n\nCode\nsurvey::svyglm(vote ~ trstprl + gender + age, family=quasibinomial, design = design2) %&gt;%\n  jtools::plot_coefs(exp=T,\n                     coefs = c(\"Trust in parliament\" = \"trstprl\",\n                               \"Gender(ref=male)\" = \"genderMale\",\n                               \"Age 25-35(ref=18-25)\" = \"age25 to 35\",\n                               \"Age 36-49(ref=18-25)\" = \"age36 to 49\",\n                               \"Age 50-64(ref=18-25)\" = \"age50 to 64\",\n                               \"Age 65+(ref=18-25)\" = \"age65+\"))"
  },
  {
    "objectID": "part2/part_2-2.html#plotting-predicted-values",
    "href": "part2/part_2-2.html#plotting-predicted-values",
    "title": "2.2: Extensions",
    "section": "Plotting predicted values",
    "text": "Plotting predicted values\nBeyond coefficients, predicted values can be plotted and evaluated.\nLet us go back and create a model for predicting news consumption using OLS regression to see effect plots for continuous outcomes.\nI theorise that trust is parliament is predictive of increased news consumption, and wish to control for age and gender.\n\n\nCode\nm2 &lt;- survey::svyglm(nwspol ~ age + gender + trstprl, family=gaussian, design=design2)\n\n\nWe can go back and look at the model summary.\n\n\nCode\nm2 %&gt;%\n  tbl_regression(exponential=T,label = c(trstprl~\"Trust in parliament\")) %&gt;%\n  add_glance_table(include=c(everything())) %&gt;%\n  bold_p(t=0.05)\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    age\n\n\n\n        18 to 25\n—\n—\n\n        25 to 35\n5.4\n-5.9, 17\n0.4\n        36 to 49\n3.9\n-6.1, 14\n0.4\n        50 to 64\n17\n6.2, 28\n0.002\n        65+\n40\n31, 50\n&lt;0.001\n    gender\n\n\n\n        Female\n—\n—\n\n        Male\n8.0\n2.9, 13\n0.002\n    Trust in parliament\n0.38\n-0.83, 1.6\n0.5\n    Null deviance\n1,269,936,326\n\n\n    Null df\n46,606\n\n\n    AIC\n599,723\n\n\n    BIC\n1,259,242,848\n\n\n    Deviance\n1,259,242,773\n\n\n    Residual df\n20,956\n\n\n    No. Obs.\n46,607\n\n\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nIt looks like my predicted relationship is not supported by the model.\nNevertheless, we can investigate the model fit and predicted values.\nFirst, we can use an effect plot to look at the predicted relationship between trust in parliament and news consumption.\n\n\nCode\njtools::effect_plot(m2, pred=trstprl, interval = T)\n\n\n\n\n\nThe error bars are very large, which makes sense because this was not a statistically significant relationship in the model.\nCalling plot on the data object provides a host of residuals plots.\n\n\nCode\nplot(m2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe qqplot indicates that the fit gets worse for the top quantiles.\nThe Scale-Location plot does not raise significant alarm bells for homoscedasticity."
  },
  {
    "objectID": "part2/part_2-2.html#your-turn",
    "href": "part2/part_2-2.html#your-turn",
    "title": "2.2: Extensions",
    "section": "Your turn!",
    "text": "Your turn!\nPractice your own survey data analysis and extensions… There are many!\nI hope these workshop materials were helpful in some way."
  },
  {
    "objectID": "part1/part_1-3.html",
    "href": "part1/part_1-3.html",
    "title": "1.3: Survey adjusted plots",
    "section": "",
    "text": "This section covers data visualisations using survey design-adjusted plots."
  },
  {
    "objectID": "part1/part_1-3.html#load-data",
    "href": "part1/part_1-3.html#load-data",
    "title": "1.3: Survey adjusted plots",
    "section": "Load data",
    "text": "Load data\nRemember that we “saved” our wrangled dataset to the working directory in the previous section as an RData file in our workshop folder.\n\n\nCode\nroot &lt;- \"C://Users//s1769862//OneDrive - University of Edinburgh//SLTF-workshop-August2024//\" # change with where the folder lies in your filepath\ncws &lt;- readRDS(file= file.path(root, \"Data\", \"cws.RData\"))\n\n\n\n\nCode\ndesign1 &lt;- survey::svydesign(ids = ~SchoolRef, strata =~Strata, weights = ~Weight, data =cws, check.strata=T)"
  },
  {
    "objectID": "part1/part_1-3.html#intro-to-plots",
    "href": "part1/part_1-3.html#intro-to-plots",
    "title": "1.3: Survey adjusted plots",
    "section": "Intro to plots",
    "text": "Intro to plots\nWe want to take advantage of R’s good graphics but the typical plotting options, e.g. base R plot or ggplot2, are not coded to intake a survey design object to make their calculations. This means that weighted estimates and standard error visualisations will be incorrect.\nTherefore, we need to specify the sampling design in the plotting arguments."
  },
  {
    "objectID": "part1/part_1-3.html#using-only-the-survey-package",
    "href": "part1/part_1-3.html#using-only-the-survey-package",
    "title": "1.3: Survey adjusted plots",
    "section": "Using only the survey package",
    "text": "Using only the survey package\nThe survey package has inbuilt plotting functions that work out-the-box.\n\n\n\n\n\n\nNote\n\n\n\nInclude ~1 to specify the lack of a second variable in univariate plots.\n\n\n\n\nCode\nsurvey::svyhist(FeelPositiveFuture~1,design1)\n\n\n\n\n\nLooking at the range, the distribution of positive feeling is right-skewed.\nThe syntax is very similar for a boxplot.\nWe can also perform some basic modification, including adding a main title with main = \"title\" .\n\n\nCode\nsurvey::svyboxplot(FeelPositiveFuture~1,design1,\n                   main = \"Feelings of positivity for the future, 12 year olds in England\")\n\n\n\n\n\n\nMultivariate plots\nTo investigate bivariate relationships with a boxplot we can replace the ~1 with a categorical variable.\n\n\nCode\nsurvey::svyboxplot(FeelPositiveFuture~HomeType,design1,\n                   main = \"Feelings of positivity by living situation, 12 year olds in England\")\n\n\n\n\n\nIt appears that there is greater variance in feelings of optimism for those in a type of home other than a family or fostering situation.\n\n\nCode\nsurvey::svyplot(FeelPositiveFuture~SatisfiedHealth,\n                design1,\n                xlab = \"Satisfaction with health\",\n                ylab = \"Feelings of positivity\",\n                main = \"Relationship between health satisfaction and positivity\",\n                style=\"grayhex\")"
  },
  {
    "objectID": "part1/part_1-3.html#task-6",
    "href": "part1/part_1-3.html#task-6",
    "title": "1.3: Survey adjusted plots",
    "section": "Task 6",
    "text": "Task 6\nNow, try out your own svy plotting options!\nKey functions for main plot types include:\n\nsvyhist\nsvybox\nsvyplot\n\n\nAdvanced: try to create both univariate and multivariate plots!\n\n\n\nCode\n## write your own code!\n\n## tip: copy and past from previous code chunks!"
  },
  {
    "objectID": "part1/part_1-3.html#better-plots",
    "href": "part1/part_1-3.html#better-plots",
    "title": "1.3: Survey adjusted plots",
    "section": "Better plots",
    "text": "Better plots\nThe survey plots are great, but they are pretty basic. I also find the syntax non-intuitive.\nThe ggsurvey function offers an excellent range of options for plotting with complex survey design. It is part of the larger questionr package, which packages several survey functions.\nggsurvey is (to my understanding!) akin to wrapper for ggplot2 that incorporates the estimate corrections provided by survey package calculations. Therefore, if you already know ggplot grammar, you know how to make survey design corrected plot 1.\nThe hegemony of ggplot grammar also makes it much easier to get help debugging your plots on forums like Stack Overflow.\n\n\nCode\nggsurvey(design1) +\n    aes(x = FrequencyHelpHousework, fill = Gender) +\n    geom_bar(position = \"fill\") +\n  labs(title = \"Frequency of housework by gender\",\n       subtitle = \"Children in England, aged 12\",\n       caption = \"Data drawn from age 12 of the Children's Worlds Survey\")\n\n\n\n\n\nAs with other ggplot2 objects, we can make this a lot prettier by customising the colour schemes and themes.\nWe can see what colour schemes are available from RColorBrewer using\n\n\nCode\nRColorBrewer::display.brewer.all()\n\n\n\n\n\n\n\nCode\nggsurvey(design1) +\n    aes(x = FrequencyHelpHousework, fill = Gender) +\n    geom_bar(position = \"fill\") + scale_fill_brewer(palette = \"Blues\") +\n  labs(title = \"Frequency of housework by gender\",\n       subtitle = \"Children in England, aged 12\",\n       caption = \"Data drawn from age 12 of the Children's Worlds Survey\")\n\n\n\n\n\nWe can also utilise the ggthemes package for pre-set colour schemes and other plotting options.\n\n\nCode\nggsurvey(design1) +\n    aes(x = FrequencyHelpHousework, fill = Gender) +\n    geom_bar(position = \"fill\") + scale_fill_brewer(palette = \"Blues\") +\n  labs(title = \"Frequency of housework by gender\",\n       subtitle = \"Children in England, aged 12\",\n       caption = \"Data drawn from age 12 of the Children's Worlds Survey\") +\n  ggthemes::theme_economist_white()\n\n\n\n\n\n\nChanging geometries\nThere are many geometries available, including boxplots.\n\n\n\n\n\n\nImportant\n\n\n\nThe boxplot geometry requires an underlying package quantreg which is not currently included in the original install. If your are getting an error check to ensure that this package is installed and loaded in your R session.\n\n\n\n\nCode\nggsurvey(design1) +\n    aes(y=FeelPositiveFuture,\n        x=HomeType,\n        fill=HomeType) + geom_boxplot() +\n  scale_fill_brewer(palette = \"Paired\") + theme_classic() +\n  labs(title = \"Feelings of positivity by living situation\",\n       subtitle = \"Children in England, aged 12\",\n       caption = \"Data drawn from age 12 of the Children's Worlds Survey\")"
  },
  {
    "objectID": "part1/part_1-3.html#task-7",
    "href": "part1/part_1-3.html#task-7",
    "title": "1.3: Survey adjusted plots",
    "section": "Task 7",
    "text": "Task 7\n\nMake your own plot!\n\n\nTry customising colours, labels, or types!\n\nLook at the data documentation for questionr (the ggsurvey function is located on page 18) and ggplot2 and more ggplot2, including cheat sheets\n\n\nCode\n## write your own code! Look at the previous chunks for help.\n\n\n\n\n\n\n\n\nNext: Go to Part 2.1: Regressions"
  },
  {
    "objectID": "part1/part_1-3.html#footnotes",
    "href": "part1/part_1-3.html#footnotes",
    "title": "1.3: Survey adjusted plots",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDouble-check the data documentation for plots with more complicated statistics, e.g. geom smooth functions.↩︎"
  },
  {
    "objectID": "part1/part_1-1.html",
    "href": "part1/part_1-1.html",
    "title": "1.1: Data import and wrangling",
    "section": "",
    "text": "This sections covers: importing, transforming and wrangling the Children’s Worlds Survey, England data from 2013/14.\nWelcome to the morning session!"
  },
  {
    "objectID": "part1/part_1-1.html#packages",
    "href": "part1/part_1-1.html#packages",
    "title": "1.1: Data import and wrangling",
    "section": "Packages",
    "text": "Packages\nIf you have not already loaded the previously specified packages please do so."
  },
  {
    "objectID": "part1/part_1-1.html#data-import",
    "href": "part1/part_1-1.html#data-import",
    "title": "1.1: Data import and wrangling",
    "section": "Data import",
    "text": "Data import\nWe will import the first dataset, the Children’s Worlds Survey.\nData with a complex survey design is often stored in data files formatted for SPSS or Stata. In this case, we downloaded the Children’s Worlds Survey as Stata .dta files. We will be utilising the haven package from the Tidyverse suite to read this format into R.\nFirst, we set a “root” which tells R where to look for the data on your computer. Change the root value to the location where you saved the data files on your machine.\n\n\nCode\nroot &lt;- \"C://Users//s1769862//OneDrive - University of Edinburgh//SLTF-workshop-August2024//\"\n# change with where the folder lies in your filepath\n\n\nNow, load the 12-year-old questionnaires from the Children’s Worlds Survey using the syntax haven::read_dta(\"file\").\nIf you downloaded the .dta file as a single folder from UKDS the data can be imported with this relative file path and the root directory specified above.\n\n\nCode\ncws &lt;- haven::read_dta(file.path(root, \"7910stata11\", \"UKDA-7910-stata11\", \"stata11\", \"children_worlds_wave2_england_12yo.dta\"))"
  },
  {
    "objectID": "part1/part_1-1.html#data-summary",
    "href": "part1/part_1-1.html#data-summary",
    "title": "1.1: Data import and wrangling",
    "section": "Data summary",
    "text": "Data summary\nFirst, let’s see what our imported .dta file looks like!\n\n\nCode\nhead(cws, n=5)\n\n\n# A tibble: 5 × 140\n   QRef SchoolRef Strata         Weight Age      Gender  BornThisCountry NHomes \n  &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl+lbl&gt;       &lt;dbl&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+lbl&gt;       &lt;dbl+l&gt;\n1 20036        30 4 [Stratum 4 …  0.792 12 [12 … 1 [Boy] 1 [Yes]         2 [I u…\n2 20037        30 4 [Stratum 4 …  0.792 12 [12 … 1 [Boy] 1 [Yes]         1 [I a…\n3 20038        30 4 [Stratum 4 …  1.14  12 [12 … 2 [Gir… 1 [Yes]         3 [I r…\n4 20039        30 4 [Stratum 4 …  0.792 12 [12 … 1 [Boy] 1 [Yes]         1 [I a…\n5 20040        30 4 [Stratum 4 …  0.792 13 [13 … 1 [Boy] 1 [Yes]         3 [I r…\n# ℹ 132 more variables: HomeType &lt;dbl+lbl&gt;, FirstHomeMother &lt;dbl+lbl&gt;,\n#   FirstHomeFather &lt;dbl+lbl&gt;, FirstHomeMPartner &lt;dbl+lbl&gt;,\n#   FirstHomeFPartner &lt;dbl+lbl&gt;, FirstHomeGrandmother &lt;dbl+lbl&gt;,\n#   FirstHomeGrandfather &lt;dbl+lbl&gt;, FirstHomeSiblings &lt;dbl+lbl&gt;,\n#   FirstHomeOtherChildren &lt;dbl+lbl&gt;, FirstHomeOtherAdults &lt;dbl+lbl&gt;,\n#   SecondHomeMother &lt;dbl+lbl&gt;, SecondHomeFather &lt;dbl+lbl&gt;,\n#   SecondHomeMPartner &lt;dbl+lbl&gt;, SecondHomeFPartner &lt;dbl+lbl&gt;, …\n\n\nWe can also view the dataset within our RStudio IDE using View, which is similar to the Stata Browse function."
  },
  {
    "objectID": "part1/part_1-1.html#task-1",
    "href": "part1/part_1-1.html#task-1",
    "title": "1.1: Data import and wrangling",
    "section": "Task 1",
    "text": "Task 1\nGet familiar with the data!\n\nWhat kinds of variables are there?\nHow are they coded?\n\n\n\nCode\n## write your own code!\n\n\n\n\n\n\n\n\nTip\n\n\n\nSome useful functions include: summary , tail , and View."
  },
  {
    "objectID": "part1/part_1-1.html#variable-classification",
    "href": "part1/part_1-1.html#variable-classification",
    "title": "1.1: Data import and wrangling",
    "section": "Variable classification",
    "text": "Variable classification\nLooking at the data summary, many variables say &lt;dbl+lbl&gt; above them. We can query more information by investigating the data class registered for any column in the dataset.\n\n\nCode\nclass(cws$FeelingHappy)\n\n\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n\nWe can see that the column is called a “Haven-labelled” class. This is a special type of data storage the .dta files are imported. Haven-labelled variables retain the metadata of the column and value labels as we would utilise them in Stata.\n\n\n\n\n\n\nNote\n\n\n\nThe logical and assumptions for how variable information is stored and inputed into statistical models differ between typical workflows in R and Stata.\nI, personally, do not like working with .dta files in R. If I plan to complete all of the project analyses in R I would download the data as .tab or .csv and utilise data documentation for all of the metadata information stored in .dta files.\nHowever, many complex survey analysts may have a background in Stata or already have their data stored in .dta files. Therefore, it is useful to know how to to wrangle these files.\n\n\nMany data analysis functions in R do not play with this data storage. We need more “basic” storage types, e.g. numeric, integer, factor or character.\nWe can remove the haven labelling using the labelled package.\n\n\nCode\nlabelled::val_labels(cws) &lt;- NULL # remove the labels\n\nclass(cws$FeelingHappy) # Test if a column was correctly converted from a double labelled type to standard numeric\n\n\n[1] \"numeric\"\n\n\nWe can see that the variable “FeelingHappy” is now successfully converted to a numeric variable."
  },
  {
    "objectID": "part1/part_1-1.html#missing-data",
    "href": "part1/part_1-1.html#missing-data",
    "title": "1.1: Data import and wrangling",
    "section": "Missing data",
    "text": "Missing data\nNext, we need to recode missing values or invalid responses to NA. The NA is equivalent to the . for Stata users.\nSocial survey datasets are often encoded with extreme numeric values to indicate missing data, e.g. -999. Consulting the Data Documentation, values 99, 95, 90 and 91 represent missing data across all columns in this dataset.\n\n\nCode\n## set all missing values to NA for the data frame\ncws[cws==99] &lt;- NA\ncws[cws==95] &lt;- NA\ncws[cws==90] &lt;- NA\ncws[cws==91] &lt;- NA"
  },
  {
    "objectID": "part1/part_1-1.html#factor-data",
    "href": "part1/part_1-1.html#factor-data",
    "title": "1.1: Data import and wrangling",
    "section": "Factor data",
    "text": "Factor data\nWe will also convert our main categorical variables from numeric numbers to factors. This means that our information should be stored as categorical information.\nAs with missing values, we may need to consult the datasets codebook or other documentation to correctly associate the numeric values with the ordinal or nominal categories which they represent.\n\n\n\n\n\n\nTip for Stata Users\n\n\n\nI often have the .dta file open in a Stata session just to read the value labels as I recode key variables in R if I find the dataset codebooks cumbersome.\nDo whatever works for you!\n\n\nThe following code writes functions which recode variables to factors based upon the labels associated with their numeric values.\n\n\nCode\ncws &lt;- cws %&gt;%\n  dplyr::mutate(Gender = as.factor(case_when(Gender == 1 ~ \"Boy\",\n                                             Gender == 2 ~ \"Girl\")),\n                NHomes = as.factor(case_when(NHomes == 1 ~ \"One home\",\n                                             NHomes == 2 ~ \"Sometimes sleep other places\",\n                                             NHomes == 3 ~ \"2 homes\")),\n                HomeType = as.factor(case_when(HomeType == 1 ~ \"Family\",\n                                               HomeType == 2 ~ \"Foster\",\n                                               HomeType == 3 ~ \"Children's home\",\n                                               HomeType == 4 ~ \"Other type\")))\n\n## define recoding functions for common value patterns to the dataset\nrecode.binary &lt;- function(x) {\n  as.factor(case_when(x == 0 ~ \"No\",\n                      x == 1 ~ \"Yes\"))} # define a function that recodes multiple columns with same value categories\n\nrecode.semi.binary &lt;- function(x) {\n  as.factor(case_when(x == 0 ~ \"No\",\n                      x == 1 ~ \"Not sure\",\n                      x == 2 ~ \"Yes\"))} # define a function for questions with \"No\", \"Not sure\", and \"Yes\" answers\n\nrecode.frequency &lt;- function(x) {\n  as.factor(case_when(x == 0 ~ \"Not at all\",\n                      x == 1 ~ \"Once or twice\",\n                      x == 2 ~ \"Most days\",\n                      x == 3 ~ \"Every day\"))\n}\n\nrecode.likert &lt;- function(x) {\n  as.factor(case_when(x == 0 ~ \"Do not agree\",\n                      x == 1 ~ \"Agree a little\",\n                      x == 2 ~ \"Agree somewhat\",\n                      x == 3 ~ \"Agree a lot\",\n                      x == 4 ~ \"Totally agree\"))\n}\n\nrecode.frequency2 &lt;- function(x) {\n  as.factor(case_when(x == 0 ~ \"Never\",\n                      x == 1 ~ \"Once\",\n                      x == 2 ~ \"2 or 3 times\",\n                      x == 3 ~ \"More than 3 times\"))\n}\n\nrecode.frequency3 &lt;- function(x) {\n  as.factor(case_when(x == 0 ~ \"Rarely or never\",\n                      x == 1 ~ \"Less than weekly\",\n                      x == 2 ~ \"Once or twice a week\",\n                      x == 3 ~ \"About every day\"))\n}\n\nrecode.frequency4 &lt;- function(x) {\n  as.factor(case_when(x == 0 ~ \"Never\",\n                      x == 1 ~ \"Hardly ever\",\n                      x == 2 ~ \"Sometimes\",\n                      x == 3 ~ \"Often\",\n                      x == 4 ~ \"Always\"))\n}\n\n## apply the recoding functions\ncws &lt;- cws %&gt;%\n  mutate(across(c(HaveTV, HaveCar, HaveMobilePhone, HaveOwnRoom, HaveAccessComputer, HaveAccessInternet, PastYearChangedArea, PastYearMovedHouse, PastYearChangedSchool, PastYearOtherCountry, BornThisCountry, HaveGoodClothes, HaveBooks), recode.binary)) %&gt;%\n  mutate(across(c(HeardOfUNCRC, KnowRights, AdultsRespectChildRights), recode.semi.binary)) %&gt;%\n  mutate(across(c(HomeSafe, HomePlaceToStudy, ParentsListen, FamilyGoodTimeTogether, ParentsTreatFairly, FriendsNice, FriendsEnough, AreaPlacesToPlay, AreaSafeWalk, TeachersListen, LikeSchool, TeachersFair, SchoolSafe), recode.likert)) %&gt;%\n  mutate(across(c(FrequencyFamilyTalk, FrequencyFamilyFun, FrequencyFamilyLearn, FrequencyFriendsTalk, FrequencyFriendsFun, FrequencyFriendsStudy), recode.frequency)) %&gt;%\n  mutate(across(c(FrequencyPeersHit, FrequencyPeersExclude), recode.frequency2)) %&gt;%\n  mutate(across(c(FrequencyClasses, FrequencyOrganisedLeisure, FrequencyReadFun, FrequencyHelpHousework, FrequencyHomework, FrequencyWatchTV, FrequencySportsExercise, FrequencyUseComputer, FrequencyByMyself, FrequencyCareForFamily), recode.frequency3)) %&gt;%\n  mutate(across(c(ParentsHelpProblems, ParentsAskWhereGoing, ParentsKeepTrackSchool, ParentsRemindWashShower, ParentsShowInterestSchool, ParentsSupportUpset, ParentsSupportUpset, ParentsKnowWhereAfterSchool, ParentsEnsureSeeDoctor), recode.frequency4))"
  },
  {
    "objectID": "part1/part_1-1.html#task-2",
    "href": "part1/part_1-1.html#task-2",
    "title": "1.1: Data import and wrangling",
    "section": "Task 2",
    "text": "Task 2\nInvestigate the data again!\n\nDo the variable recodes “make sense”?\nIs there any other variable cleaning required?\n\n\n\nCode\n## write your own code!\n\n\n\nJust like that, we have a “clean” dataset, fully converted from .dta to a data frame that we can work with in R."
  },
  {
    "objectID": "part1/part_1-1.html#save-data",
    "href": "part1/part_1-1.html#save-data",
    "title": "1.1: Data import and wrangling",
    "section": "Save data",
    "text": "Save data\nSave the changed data.frame as an RData file.\nThis step is superfluous if you are working within one data analysis script. However, this workshop has been broken up into more digestible chunks. Therefore, we need our data to be transportable between the files.\nFor this reason, I have created a folder called Data and placed it in my root directory.\nTo save our dataset object to this folder execute the follow chunk:\n\n\nCode\nsaveRDS(cws, file = file.path(root, \"Data\", \"cws.RData\"))\n\n\n\n\n\n\n\n\nNext: Go to Part 1.2: Survey adjusted descriptive statistics"
  },
  {
    "objectID": "part-1.html",
    "href": "part-1.html",
    "title": "Part 1",
    "section": "",
    "text": "1.1: Data import and wrangling\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n1.2: Survey adjusted descriptive statistics\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n1.3: Survey adjusted plots\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Set up",
    "section": "",
    "text": "This is a brief introduction to setting up your workflow, downloading the datasets and associated packages.\nI recommend working through this introduction if you need a refresher on R and R Studio."
  },
  {
    "objectID": "data.html#working-directory",
    "href": "data.html#working-directory",
    "title": "Set up",
    "section": "Working directory",
    "text": "Working directory\nThis quarto website is designed to contain all of the code and output to complete the learning tasks.\nThe project folder containing all .qmd files required for this tutorial should be downloaded and run on your own computer to complete the activity.\nTo set-up your workflow correctly, please…\n\nEnsure that you have a recent version of ‘R’ downloaded from r-project.org. This workshop was built with R version 4.4.1 (Race for Your Life).\nDownload R Studio.\nCreate a workshop folder in your local field system.\nDownload all .qmd files from the workshop github and save them to your workshop folder.\nSet your working directory to the workshop folder.\n\n\ngetwd() # retrieve your current working directory\nsetwd(\"some path on your computer\") # set your working directory using your personal file paths"
  },
  {
    "objectID": "data.html#packages",
    "href": "data.html#packages",
    "title": "Set up",
    "section": "Packages",
    "text": "Packages\nThe required packages and versions utilised in this workshop should be located in the project renv. Without version control, they can also be installed and located using the following code.\n\n## install packages\n#install.packages(\"survey\")\n#install.packages(\"haven\")\n#install.packages(\"labelled\")\n#install.packages(\"dplyr\")\n#install.packages(\"questionr\")\n#install.packages(\"gtsummary\")\n#install.packages(\"ggthemes\")\n#install.packages(\"RColorBrewer\")\n#install.packages(\"jtools\")\n#install.packages(\"hexbin\")\n#install.packages(\"quantreg\")\n\n## load packages into your global environment\nlibrary(survey) # handling survey data with complex sampling design\nlibrary(haven) # for reading in non-native data formats (e.g. Stata's .dta files)\nlibrary(labelled) # working with labelled data\nlibrary(dplyr) # data manipulation\nlibrary(ggplot2) # data visualisation\nlibrary(questionr) # data visualisation with survey design objects\nlibrary(gtsummary) # nice publication ready summary tables\nlibrary(ggthemes) # change theme of ggplot objects\nlibrary(RColorBrewer) # for color schemes\nlibrary(jtools) # visualising regression results\nlibrary(hexbin) # assist with plotting graphics\nlibrary(quantreg) # supports boxplot functions for ggsurvey"
  },
  {
    "objectID": "data.html#data",
    "href": "data.html#data",
    "title": "Set up",
    "section": "Data",
    "text": "Data\nThis workshop utilises data from two repositories: the UK Data Service (UKDS) and the European Social Survey (ESS). Both datasets are open access but require that you make an account with the associated repositories.\nWe will load two datasets that feature different sampling designs and information in the data documentation to practice loading, reading about the methodology, and encoding this information in the survey design object.\n\n\nDataset 1: The Children’s Worlds Survey\n\nStep 1: Register with the UKDS\n\nNavigate to the UKDS login channel.\nIf you are a member of a UK research organisation, login through your institution. If not, you will need to request a username and then sign-in here.\n\n\n\nStep 2: Download the dataset\n\nGo to the data browser and search for the study identifier “SN 7910” for the Children’s Worlds Survey: England, 2013-2014\nEnsure the doi matches: 10.5255/UKDA-SN-7910-1\nPress “Access data” and download the Stata .dta format.\nUnzip the folder and place in your workshop folder.\n\n\n\n\nDataset 2: The European Social Survey\n\nStep 1: Register with the ESS\n\nGo to the ESS Data Portal\nPress “login” and “make an account”\nOnce you have made an account, login.\n\n\n\nStep 2: Download the dataset\n\nLocate the ESS round 9 - 2018. Timing of life, Justice and fairness\nEnsure the doi matches 10.21338/ess9e03_2\nPress “Download” and select the .csv format.\nUnzip the folder and place in your workshop folder.\n\n\n\n\n\n\n\nNext: Go to Part 1.1: Data import and wrangling"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Maddi  and I am a PhD Student in Social Policy at the University of Edinburgh.\nMy research utilises the Growing Up in Scotland (GUS) birth cohort study. Like many popular social surveys, GUS has a complex sampling design. In the beginning of my PhD, I spent a lot of time learning how to approach statistical analyses with the unique requirements imposed by this type of data.\nI made a lot of mistakes along the way, and wished for a guide on approaching survey research in R that was written to speak to someone like me: a social scientist armed with only a passable grasp of Stata and my study’s data documentation.\nI hope that these workshop materials will be use of to someone else!\n\nThe website is made with Quarto. To learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Complex survey data in R",
    "section": "",
    "text": "This quarto website hosts all of the learning materials for the workshop “Introduction to Working with Complex Survey Data in R”, which is set to run on the 20th of August, 2024.\nFunding for this workshop was provided by the UK Economic and Social Research Council (ESRC) and Scottish Funding Council as part of the Scottish Graduate School of Social Science (SGSSS) 2023/24 training programme."
  },
  {
    "objectID": "index.html#summary",
    "href": "index.html#summary",
    "title": "Complex survey data in R",
    "section": "",
    "text": "This quarto website hosts all of the learning materials for the workshop “Introduction to Working with Complex Survey Data in R”, which is set to run on the 20th of August, 2024.\nFunding for this workshop was provided by the UK Economic and Social Research Council (ESRC) and Scottish Funding Council as part of the Scottish Graduate School of Social Science (SGSSS) 2023/24 training programme."
  },
  {
    "objectID": "index.html#problem-statement",
    "href": "index.html#problem-statement",
    "title": "Complex survey data in R",
    "section": "Problem statement",
    "text": "Problem statement\nMany popular social science datasets are collected with complex sampling designs which violate the basic assumptions of a simple random sample.\nTraditional approaches have required proprietary software, such as Stata or Mplus, to accommodate complex sampling. Thomas Lumley’s Survey package for R changed the game, providing an open source alternative.\nThis tutorial serves as in introduction to analysing datasets with complex sampling and/or weighting requirements."
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "Complex survey data in R",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nKey learning outcomes include:\n\nImport and wrangle .dta data files in R\nSet a survey design object\nEstimate and report descriptive statistics using survey weighting\nData visualisation using survey weighting\nRegression models with complex sampling"
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Complex survey data in R",
    "section": "Resources",
    "text": "Resources\nIn the first instance, please reference the data documentation for the packages utilised in this workshop.\n\nsurvey\ngtsummary\ntidyverse, particularly dplyr and ggplot2\nquestionr\njtools"
  },
  {
    "objectID": "part-2.html",
    "href": "part-2.html",
    "title": "Part 2",
    "section": "",
    "text": "2.1: Regressions\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n2.2: Extensions\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "part1/part_1-2.html",
    "href": "part1/part_1-2.html",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "",
    "text": "This section covers: creating a survey design object, adjusted descriptive statistics and tables!"
  },
  {
    "objectID": "part1/part_1-2.html#load-data",
    "href": "part1/part_1-2.html#load-data",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Load data",
    "text": "Load data\nRemember that we saved the wrangled dataset to the working directory in the previous section as an RData file in our workshop folder.\n\n\nCode\nroot &lt;- \"C://Users//s1769862//OneDrive - University of Edinburgh//SLTF-workshop-August2024//\" # change with where the folder lies in your filepath\ncws &lt;- readRDS(file= file.path(root, \"Data\", \"cws.RData\"))"
  },
  {
    "objectID": "part1/part_1-2.html#sampling-design",
    "href": "part1/part_1-2.html#sampling-design",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Sampling design",
    "text": "Sampling design\nHow do we handling the sampling design of this survey? First, we read the Data Documentation to learn more about the methodology and any population correcting weighting that we can apply.\nTake a minute to search for this information on your own. What clues can you draw out?\n\nLooking at the documentation, some key elements appear to be….\n\n1.2 Sampling strategy and outcomes (pg. 4)\n“The England sample was designed to achieve a nationally representative sample of children in school….. The primary sampling unit was schools. Separate samples were drawn for Years 4 and 6 (primary school education) and Year 8 (secondary school education). Both samples followed the same methodology. First, a complete list of schools in England was stratified into five groups by the proportion of children receiving free school meals (a very rough indicator of economic prosperity).”\n\n\n“These groups were approximate quintiles (based on numbers of pupils in each stratum). The approximation was because of a lack of precision in the data available on free school meal entitlement. Within each stratum schools were selected randomly with probabilities proportional to size (number of pupils), with the aim of achieving a target of at least eight schools per stratum. Within each selected school, one class group (not grouped on pupil ability) was randomly selected.”\n\n\nReading this paragraph, we can see that this dataset has…\n\nEngland divided into five stratum\nSchools are the primary sampling unit within each stratum\nIndividual weights to readjust for sample representativeness\n\nFrom this information, we can create what is called a “survey design object”. This is where the survey design information is encoded into our R working environment and can be called into other statistical functions.\n\n\n\n\n\n\nNote\n\n\n\nWe can also look at the Survey package documentation for more details and help using ?? survey or help(svydesign) into the console\n\n\n\nidsprobsstratafpcweightdata\n\n\nThe “ids” indicates the primary sampling unit (PSU). This can be thought of as the smallest unit which individuals are sampled from.\n\n\nFormula for cluster sampling probabilities.\n\n\nHow the population was originally divided.\n\n\nFinite population correction.\n\n\nThe individual probability of selection.\n\n\nThe name of the data frame in R working memory.\n\n\n\nIn our dataset the column names for these are:\n\nids: SchoolRef\nstrata: Strata\nweights: Weight\ndata: cws 1.\n\nWe do not have a finite population correction or cluster sampling probability information, so we leave these fields blank.\n\n\n\n\n\n\nTip\n\n\n\nWe also include “check.strata = TRUE” as a sense check to ensure that our primary sampling units (the schools) are all nested within our strata. This should return nothing if all is well.\n\n\n\n\nCode\ndesign1 &lt;- survey::svydesign(ids = ~SchoolRef, strata =~Strata, weights = ~Weight, data =cws, check.strata=T)\n\n\nWe now have a survey design object which stores both our original dataset and the encoded information about its sampling and weighting."
  },
  {
    "objectID": "part1/part_1-2.html#descriptive-statistics",
    "href": "part1/part_1-2.html#descriptive-statistics",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\nNow, we can start to use the survey design object to display statistics that are adjusted for the sampling design and weighting.\n\n\nCode\nsurvey::svymean(~LifeGoingWell, design1, na.rm=TRUE)\n\n\n                mean     SE\nLifeGoingWell 8.3951 0.1027\n\n\nLet’s compare these to the unweighted version, using “base” r.\nHow does accounting for the sampling design and population weighting change our estimates?\n\n\nCode\n# estimate un-weighted mean and sd \nbase::mean(cws$LifeGoingWell, na.rm=T) # mean\n\n\n[1] 8.451588\n\n\nCode\n## compare with survey weighted estimates\n(survey::svymean(~LifeGoingWell, design1, na.rm=T)) - (mean(cws$LifeGoingWell, na.rm=T)) # can see a modest correction in the estimate\n\n\n                   mean     SE\nLifeGoingWell -0.056477 0.1027\n\n\nComparing the two estimates, we can see that the estimate for “life going well” is slightly lower for the population estimates compared to the face-value calculation.\nVariance and standard error\nWe can also see that the standard error around the mean is larger for the survey weighted result. Therefore, our error estimates would be underestimated if we assumed a simple random sample and ignored the sampling design.\n\n\nCode\nsd((cws$LifeGoingWell), na.rm=TRUE)/sqrt(length(!is.na(cws$LifeGoingWell))) # standard error\n\n\n[1] 0.05800934\n\n\n\n\nCode\nsurvey::svyvar(~LifeGoingWell, design1, na = TRUE) # survey weighted estimate\n\n\n              variance     SE\nLifeGoingWell   4.6378 0.4703\n\n\nDeciles\nUnfortunately, the decile results do not display well in the .quarto website output. However, I recommend that you run these lines on your own machine to see the raw output\n\n\nCode\nsurvey::svyquantile(~LifeGoingWell, design1, na = TRUE, c(.25,.5,.75),ci=TRUE)\n\n\n\n\nCode\nsurvey::svyquantile(~LifeGoingWell, design1, na = TRUE, c(.20,.40,.60,.80),ci=TRUE)"
  },
  {
    "objectID": "part1/part_1-2.html#tables",
    "href": "part1/part_1-2.html#tables",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Tables",
    "text": "Tables\nWe can also create adjusted tables with the survey package.\n\n\nCode\nsurvey::svytable(~LifeGoingWell, design1)\n\n\nLifeGoingWell\n         0          1          2          3          4          5          6 \n 11.810352   4.225975  16.652450  26.043925  42.924747  43.591784  60.086619 \n         7          8          9         10 \n101.180865 166.925511 241.002194 572.818609 \n\n\nWe can see how these estimates differ from the unweighted estimates provided in from the base table estimates.\n\n\nCode\nbase::table(cws$LifeGoingWell)\n\n\n\n  0   1   2   3   4   5   6   7   8   9  10 \n 10   6  14  21  41  48  61  95 166 239 590 \n\n\nTables are helpful for seeing the weighting option in our survey design object at work. However, they are not very pretty! This becomes more of a problem for larger or more complex tables, e.g. cross tabulations.\nWe also often want to present multiple types of descriptive statistics, e.g. the adjusted variance or other attributes of a distribution, within the same table.\nFor this, we need a better table package.\n\nTables with gtsummary\nWe can improve descriptive statistics summaries by utilising table packages.\nThe GT framework has a good set of table output options for descriptive statistics, bivariate and regression results.\nThe the gtsummary package is a wrapper for survey that was inspired by GT but makes some handy decisions and incorporates the survey design into the descriptive statistics reporting.\n\n\nCode\ngtsummary::tbl_svysummary(design1,\n                          include = c(\"FrequencyHelpHousework\", \"HeardOfUNCRC\"),\n                          missing_text = \"NA\")\n\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,3191\n    \n  \n  \n    FrequencyHelpHousework\n\n        About every day\n614 (48%)\n        Less than weekly\n132 (10%)\n        Once or twice a week\n440 (34%)\n        Rarely or never\n94 (7.4%)\n        NA\n38\n    HeardOfUNCRC\n\n        No\n278 (22%)\n        Not sure\n600 (47%)\n        Yes\n388 (31%)\n        NA\n53\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nWe can also make tables for continuous variables\n\n\nCode\ngtsummary::tbl_svysummary(design1,\n                          include = c(\"FeelPositiveFuture\", \"FeelingHappy\", \"PeopleFriendly\", \"LifeJustRight\"),\n                          statistic = list(all_continuous() ~ \"{mean} ({sd})\"),\n                          missing = \"no\")\n\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,3191\n    \n  \n  \n    I feel positive about my future\n8.20 (2.32)\n    Last two weeks: How often feeling happy\n8.34 (2.40)\n    People are generally pretty friendly towards me\n8.23 (2.37)\n    My life is just right\n8.14 (2.47)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\n\n\nSummary table example 2\nHere is another example comparing the weighted and unweighted summary tables for changes in household spending from the 12-year-olds’ perspectives.\nFirst, a table using base R.\n\n\nCode\nbase::table(cws$FamilyMoneyChange, exclude=F) \n\n\n\n   1    2    3 &lt;NA&gt; \n 425  316  134  444 \n\n\n\n\nCode\ngtsummary::tbl_summary(cws, include = c(\"FamilyMoneyChange\"), digits = list(all_categorical() ~ c(0, 1)))\n\n\n\n\n\n\n  \n    \n      Characteristic\n      N = 1,3191\n    \n  \n  \n    Q15 Compared to a year ago, how much money does your family have now?\n\n        1\n425 (48.6%)\n        2\n316 (36.1%)\n        3\n134 (15.3%)\n        Unknown\n444\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nIf we wish to have the categorical responses listed, rather than factor numeric values, we need to change the dataset itself.\n\n\nCode\ncws &lt;- cws %&gt;%\n  mutate(FamilyMoneyChange = as.factor(case_when(\n    FamilyMoneyChange == 1 ~ \"We have more money than a year ago\",\n    FamilyMoneyChange == 2 ~ \"We have about the same as a year ago\",\n    FamilyMoneyChange == 3 ~ \"We have less money than a year ago\")))\n\n\ngtsummary::tbl_summary(cws, include = c(\"FamilyMoneyChange\"), digits = list(all_categorical() ~ c(0, 1))) %&gt;%\n  modify_caption(\"Unweighted frequences for 12-year-olds perceptions' of family finances\") %&gt;% modify_footnote(update = everything() ~ \"Data Source: 2013/14 Childrens World Survey, England\")\n\n\n\n\n\n\n  Unweighted frequences for 12-year-olds perceptions’ of family finances\n  \n    \n      Characteristic1\n      N = 1,3191\n    \n  \n  \n    FamilyMoneyChange\n\n        We have about the same as a year ago\n316 (36.1%)\n        We have less money than a year ago\n134 (15.3%)\n        We have more money than a year ago\n425 (48.6%)\n        Unknown\n444\n  \n  \n  \n    \n      1 Data Source: 2013/14 Childrens World Survey, England\n    \n  \n\n\n\n\nIf we have changed anything in the original dataset, such as recoding a variable (even to just make it more clearly labelled!) this will not automatically updated in the survey design object. If we wish to update this, we need to recreate it with the updated dataset.\n\n\n\n\n\n\nTip\n\n\n\nIt is often best practice to complete all data manipulation (e.g. recodes) before setting the survey design object.\n\n\n\n\nCode\ndesign1 &lt;- survey::svydesign(ids = ~SchoolRef, strata =~Strata, weights = ~Weight, data =cws, check.strata=T)\n\n\nNow, if we run the same code as the previous chunk, it will updated to have the character names for our categorical variable encoded in the table.\n\n\nCode\ngtsummary::tbl_svysummary(design1, include = c(\"FamilyMoneyChange\"), digits = list(all_categorical() ~ c(0, 1))) %&gt;%\n  modify_caption(\"Weighted frequences for 12-year-olds perceptions' of family finances\") %&gt;%\n  modify_footnote(all_stat_cols() ~ \"Data Source: 2013/14 Children's World Survey, England; Survey weighting applied\")\n\n\n\n\n\n\n  Weighted frequences for 12-year-olds perceptions’ of family finances\n  \n    \n      Characteristic\n      N = 1,3191\n    \n  \n  \n    FamilyMoneyChange\n\n        We have about the same as a year ago\n339 (38.0%)\n        We have less money than a year ago\n143 (16.1%)\n        We have more money than a year ago\n410 (46.0%)\n        Unknown\n427\n  \n  \n  \n    \n      1 Data Source: 2013/14 Children’s World Survey, England; Survey weighting applied\n    \n  \n\n\n\n\n\n\n\n\n\n\nNA column\n\n\n\nNotice that the “number” of missing values has changed between the unweighted, base R table and the gtsummary table. This is because the distribution of item level non response are associated with different weightings. Larger NA estimates in the weighted tables indicate that observations which did not offer a valid response to the question have higher weighting, on average, resulting in enlarged influence of this category in the nationally representative statistics"
  },
  {
    "objectID": "part1/part_1-2.html#task-3",
    "href": "part1/part_1-2.html#task-3",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Task 3",
    "text": "Task 3\nProduce a weighted frequency table of a variable of interest.\nNow, try it yourself! Create survey weighted summary statistics for a different variables in the dataset.\n\n\n\n\n\n\nHint\n\n\n\nLook up the data documentation with help(tbl_svysymmary)\n\nWhat settings can you play around with?\nHow can you use this tool to explore your dataset?\n\n\n\n\n\nCode\n## enter your own code here\n\n\n\n## hint: copy segments from previous code chunks\n\n\nA possible solution can be viewed below:\n\n\nCode\ngtsummary::tbl_svysummary(design1, include = c(\"FamilyMoneyChange\"), digits = list(all_categorical() ~ c(0, 1))) %&gt;%\n  modify_caption(\"Weighted frequences for 12-year-olds perceptions' of family finances\") %&gt;%\n  modify_footnote(all_stat_cols() ~ \"Data Source: 2013/14 Children's World Survey, England; Survey weighting applied\")\n\n\n\n\n\n\n  Weighted frequences for 12-year-olds perceptions’ of family finances\n  \n    \n      Characteristic\n      N = 1,3191\n    \n  \n  \n    FamilyMoneyChange\n\n        We have about the same as a year ago\n339 (38.0%)\n        We have less money than a year ago\n143 (16.1%)\n        We have more money than a year ago\n410 (46.0%)\n        Unknown\n427\n  \n  \n  \n    \n      1 Data Source: 2013/14 Children’s World Survey, England; Survey weighting applied\n    \n  \n\n\n\n\n\nCross tabulations\nWe can also calculate cross tabulations which take into account our survey design corrections and weighting by utilising the “by” option in tbl_svysummary\n\n\nCode\ngtsummary::tbl_svysummary(design1,\n                          include = c(\"FeelPositiveFuture\", \"FeelingHappy\", \"PeopleFriendly\", \"LifeJustRight\", \"FamilyMoneyChange\"),\n                          by = FamilyMoneyChange,\n                          statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n\n\n\n\n\n\n  \n    \n      Characteristic\n      We have about the same as a year ago, N = 3391\n      We have less money than a year ago, N = 1431\n      We have more money than a year ago, N = 4101\n    \n  \n  \n    I feel positive about my future\n8.25 (2.11)\n7.30 (2.68)\n8.67 (2.12)\n        Unknown\n14\n3\n9\n    Last two weeks: How often feeling happy\n8.38 (2.12)\n7.21 (2.85)\n8.79 (2.11)\n        Unknown\n4\n4\n16\n    People are generally pretty friendly towards me\n8.32 (2.13)\n7.30 (2.88)\n8.69 (2.03)\n        Unknown\n9\n0\n3\n    My life is just right\n8.34 (2.04)\n7.05 (2.84)\n8.47 (2.37)\n        Unknown\n3\n2\n14\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\nIf we use two categorical variables instead of one categorical and one “continuous” (an ordinal Likert scale, in this case), the cross table will also compute a \\(x^2\\) statistic when we do the add_p() option.\n\n\nCode\ngtsummary::tbl_svysummary(design1, include = c(\"FrequencyWatchTV\", \"FrequencySportsExercise\"), by = FrequencyWatchTV) %&gt;%\n  modify_caption(\"Cross tabulation of time use by 12 year olds in England\") %&gt;%\n  add_p()%&gt;%\n  modify_footnote(all_stat_cols() ~ \"Data Source: 2013/14 Children's World Survey, England; Survey weighting applied\") %&gt;%\n  modify_header(label ~ \"FrequencyWatchTV\")\n\n\n\n\n\n\n  Cross tabulation of time use by 12 year olds in England\n  \n    \n      FrequencyWatchTV\n      About every day, N = 1,0561\n      Less than weekly, N = 461\n      Once or twice a week, N = 1621\n      Rarely or never, N = 161\n      p-value2\n    \n  \n  \n    FrequencySportsExercise\n\n\n\n\n&lt;0.001\n        About every day\n574 (55%)\n16 (34%)\n64 (41%)\n5 (29%)\n\n        Less than weekly\n58 (5.6%)\n13 (29%)\n18 (12%)\n0 (0%)\n\n        Once or twice a week\n345 (33%)\n11 (25%)\n67 (42%)\n9 (58%)\n\n        Rarely or never\n60 (5.8%)\n6 (13%)\n9 (5.6%)\n2 (13%)\n\n        Unknown\n20\n0\n4\n0\n\n  \n  \n  \n    \n      1 Data Source: 2013/14 Children’s World Survey, England; Survey weighting applied\n    \n    \n      2 chi-squared test with Rao & Scott’s second-order correction\n    \n  \n\n\n\n\nWe can produce a variety of bivariate test results within our gtsummary tables, including t-tests.\nA full list can be found here\n\n\nCode\ngtsummary::tbl_svysummary(design1,\n                          include = c(\"Gender\", \"SatisfiedAppearance\"),\n                          by = Gender) %&gt;%\n  modify_caption(\"Cross tabulation of satisfaction with personal appearance from 12 year olds in England, by child's gender\") %&gt;%\n  add_p(test = all_continuous() ~ \"svy.t.test\") %&gt;%\n  modify_footnote(all_stat_cols() ~ \"Data Source: 2013/14 Children's World Survey, England; Survey weighting applied\")\n\n\n\n\n\n\n  Cross tabulation of satisfaction with personal appearance from 12 year olds in England, by child’s gender\n  \n    \n      Characteristic\n      Boy, N = 6731\n      Girl, N = 6341\n      p-value2\n    \n  \n  \n    Satisfaction with: The way that you look\n9.0 (7.0, 10.0)\n7.0 (5.0, 9.0)\n&lt;0.001\n        Unknown\n11\n13\n\n  \n  \n  \n    \n      1 Data Source: 2013/14 Children’s World Survey, England; Survey weighting applied\n    \n    \n      2 t-test adapted to complex survey samples"
  },
  {
    "objectID": "part1/part_1-2.html#task-4",
    "href": "part1/part_1-2.html#task-4",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Task 4",
    "text": "Task 4\nProduce a weighted cross tabulation of two variables of interest and include an appropriate inferential test for the type of variable.\n\n\nCode\n## your code goes here\n\n\n\n\n\n\n\n\nSummary tips\n\n\n\n\nRead the dataset documentation clearly to identify all elements of the sampling design provided. Ensure there are no missing values for any columns with design information.\nIf we make any changes to our data set we need to update the survey design object.\nThe gtsummary package is great, but the syntax is confusing at first! Get used to spending time reading its helpful data documentation."
  },
  {
    "objectID": "part1/part_1-2.html#sub-setting",
    "href": "part1/part_1-2.html#sub-setting",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Sub-setting",
    "text": "Sub-setting\nPreviously we discussed that it is important to not alter the number of cases (in this case, individuals in the dataset) from the full number utilised by the data managers to calculate the survey weights.\n\nWhat happens when we change our dataset or work with a sub-sample?\n\nWe may wish to restrict our data frame due to..\n\n\n\nSet of columns\nSub-sample\n\n\n\n\nDifferent number of columns\nDifferent number of units\n\n\nNeed to specify new dataset\nNeed to specify the reduction in units\n\n\nA matter of code change\nA matter of mathematical change\n\n\n\n\n\n\n\nWe already demonstrated the latter in a previous example. Now, we explore how to conduct sub-sample analyses.\n\nSub-sample analysis: by gender\nWe create a new design object which is a subset of our original object by a condition of our choice\n\n\nCode\ndesign.subset &lt;- subset(design1, Gender == \"Boy\")\n\n\nWe can compare the number of primary sampling units (in this case schools!) between our original design and the subset\n\n\nCode\nsummary(design.subset)\n\n\nStratified 1 - level Cluster Sampling design (with replacement)\nWith (33) clusters.\nsubset(design1, Gender == \"Boy\")\nProbabilities:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2008  0.6842  1.2032  2.0543  4.2270  5.6452 \nStratum Sizes: \n             1  2   3   4   5\nobs        246 98 110 106 110\ndesign.PSU   8  7   7   6   7\nactual.PSU   7  6   7   6   7\nData variables:\n  [1] \"QRef\"                          \"SchoolRef\"                    \n  [3] \"Strata\"                        \"Weight\"                       \n  [5] \"Age\"                           \"Gender\"                       \n  [7] \"BornThisCountry\"               \"NHomes\"                       \n  [9] \"HomeType\"                      \"FirstHomeMother\"              \n [11] \"FirstHomeFather\"               \"FirstHomeMPartner\"            \n [13] \"FirstHomeFPartner\"             \"FirstHomeGrandmother\"         \n [15] \"FirstHomeGrandfather\"          \"FirstHomeSiblings\"            \n [17] \"FirstHomeOtherChildren\"        \"FirstHomeOtherAdults\"         \n [19] \"SecondHomeMother\"              \"SecondHomeFather\"             \n [21] \"SecondHomeMPartner\"            \"SecondHomeFPartner\"           \n [23] \"SecondHomeGrandmother\"         \"SecondHomeGrandfather\"        \n [25] \"SecondHomeSiblings\"            \"SecondHomeOtherChildren\"      \n [27] \"SecondHomeOtherAdults\"         \"HomeSafe\"                     \n [29] \"HomePlaceToStudy\"              \"ParentsListen\"                \n [31] \"FamilyGoodTimeTogether\"        \"ParentsTreatFairly\"           \n [33] \"ParentsHelpProblems\"           \"ParentsAskWhereGoing\"         \n [35] \"ParentsKeepTrackSchool\"        \"ParentsRemindWashShower\"      \n [37] \"ParentsShowInterestSchool\"     \"ParentsSupportUpset\"          \n [39] \"ParentsKnowWhereAfterSchool\"   \"ParentsEnsureSeeDoctor\"       \n [41] \"SatisfiedHouse\"                \"SatisfiedPeopleLiveWith\"      \n [43] \"SatisfiedOtherFamily\"          \"SatisfiedFamilyLife\"          \n [45] \"FrequencyFamilyTalk\"           \"FrequencyFamilyFun\"           \n [47] \"FrequencyFamilyLearn\"          \"FrequencyPocketMoney\"         \n [49] \"HaveGoodClothes\"               \"HaveAccessComputer\"           \n [51] \"HaveAccessInternet\"            \"HaveMobilePhone\"              \n [53] \"HaveOwnRoom\"                   \"HaveBooks\"                    \n [55] \"HaveCar\"                       \"HaveMusic\"                    \n [57] \"HaveTV\"                        \"SatisfiedThingsHave\"          \n [59] \"NumberAdultsPaidJob\"           \"FamilyMoneyChange\"            \n [61] \"ParentsSpendMoney\"             \"AdultsTalkMoneyProblems\"      \n [63] \"FriendsNice\"                   \"FriendsEnough\"                \n [65] \"SatisfiedFriends\"              \"SatisfiedPeopleArea\"          \n [67] \"SatisfiedRelationshipsGeneral\" \"FrequencyFriendsTalk\"         \n [69] \"FrequencyFriendsFun\"           \"FrequencyFriendsStudy\"        \n [71] \"AreaPlacesToPlay\"              \"AreaSafeWalk\"                 \n [73] \"SatisfiedPolice\"               \"SatisfiedDoctors\"             \n [75] \"SatisfiedOutdoorAreas\"         \"SatisfiedAreaGeneral\"         \n [77] \"TeachersListen\"                \"LikeSchool\"                   \n [79] \"TeachersFair\"                  \"SchoolSafe\"                   \n [81] \"FrequencyPeersHit\"             \"FrequencyPeersExclude\"        \n [83] \"SatisfiedClassmates\"           \"SatisfiedSchoolMarks\"         \n [85] \"SatisfiedSchoolExperience\"     \"SatisfiedLifeAsStudent\"       \n [87] \"SatisfiedThingsLearned\"        \"SatisfiedTeachers\"            \n [89] \"FrequencyClasses\"              \"FrequencyOrganisedLeisure\"    \n [91] \"FrequencyReadFun\"              \"FrequencyHelpHousework\"       \n [93] \"FrequencyHomework\"             \"FrequencyWatchTV\"             \n [95] \"FrequencySportsExercise\"       \"FrequencyUseComputer\"         \n [97] \"FrequencyByMyself\"             \"FrequencyCareForFamily\"       \n [99] \"SatisfiedTimeUse\"              \"SatisfiedFreedom\"             \n[101] \"SatisfiedOpportunities\"        \"SatisfiedHealth\"              \n[103] \"SatisfiedAppearance\"           \"SatisfiedBody\"                \n[105] \"SatisfiedFreeTime\"             \"SatisfiedListenedTo\"          \n[107] \"SatisfiedSelfConfidence\"       \"SatisfiedLifeAsWhole\"         \n[109] \"PastYearMovedHouse\"            \"PastYearChangedArea\"          \n[111] \"PastYearChangedSchool\"         \"PastYearOtherCountry\"         \n[113] \"PastYearLiveSameAdults\"        \"SatisfiedSafety\"              \n[115] \"SatisfiedThingsGoodAt\"         \"SatisfiedThingsAwayFromHome\"  \n[117] \"SatisfiedLaterInLife\"          \"SatisfiedChoice\"              \n[119] \"LifeGoingWell\"                 \"LifeJustRight\"                \n[121] \"HaveGoodLife\"                  \"HaveWhatWant\"                 \n[123] \"ThingsLifeExcellent\"           \"KnowRights\"                   \n[125] \"HeardOfUNCRC\"                  \"AdultsRespectChildRights\"     \n[127] \"LikeWayIAm\"                    \"ManageResponsibilities\"       \n[129] \"PeopleFriendly\"                \"EnoughChoiceTime\"             \n[131] \"LearningALot\"                  \"KnowWhereLifeGoing\"           \n[133] \"FeelLonely\"                    \"FeelPositiveFuture\"           \n[135] \"FeelingSatisfied\"              \"FeelingHappy\"                 \n[137] \"FeelingRelaxed\"                \"FeelingActive\"                \n[139] \"FeelingCalm\"                   \"FeelingFullOfEnergy\"          \n\n\nNotice that in the design.PSU Stratum 2 has 7 PSUs, but in the actual.PSU has 6 PSUs.\nThis is because one primary sampling unit was lost in the sub-setting, with insufficient observations remaining in the result.\nIf there were any “lonely” primary sampling units (one’s that only have one case left after sub-setting) we can adjust the “pre-sets” to allow for adjustment (get more into this later!).\n\n\nCode\noptions(survey.lonely.psu = \"adjust\")\noptions(survey.adjust.domain.lonely = TRUE)\n\n\n\n\nCode\ngtsummary::tbl_svysummary(design.subset, include = c(\"FrequencyWatchTV\", \"FrequencySportsExercise\"), by = FrequencyWatchTV) %&gt;%\n  modify_caption(\"Cross tabulation of time use by 12 year boys in England\") %&gt;% add_p()%&gt;%\n  modify_footnote(all_stat_cols() ~ \"Data Source: 2013/14 Children's World Survey, England; Survey weighting applied\") %&gt;%\n  modify_header(label ~ \"FrequencyWatchTV\")\n\n\n\n\n\n\n  Cross tabulation of time use by 12 year boys in England\n  \n    \n      FrequencyWatchTV\n      About every day, N = 5051\n      Less than weekly, N = 341\n      Once or twice a week, N = 1041\n      Rarely or never, N = 91\n      p-value2\n    \n  \n  \n    FrequencySportsExercise\n\n\n\n\n&lt;0.001\n        About every day\n330 (66%)\n13 (39%)\n43 (43%)\n2 (22%)\n\n        Less than weekly\n14 (2.8%)\n9 (25%)\n8 (7.6%)\n0 (0%)\n\n        Once or twice a week\n137 (27%)\n9 (26%)\n44 (44%)\n6 (72%)\n\n        Rarely or never\n19 (3.8%)\n3 (10%)\n6 (6.1%)\n1 (6.1%)\n\n        Unknown\n5\n0\n2\n0\n\n  \n  \n  \n    \n      1 Data Source: 2013/14 Children’s World Survey, England; Survey weighting applied\n    \n    \n      2 chi-squared test with Rao & Scott’s second-order correction"
  },
  {
    "objectID": "part1/part_1-2.html#task-5",
    "href": "part1/part_1-2.html#task-5",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Task 5",
    "text": "Task 5\nNow, try to subset your dataset by your own conditions.\n\nCreate a new sub-setted survey design object\nCreate a gtsummary table using your sub-setted data\nEnsure to properly label your table to reflect the restricted analysis\nSpend time perfecting your table, if you wish. What labels can you add? Descriptive statistics?\n\n\n\nCode\n## write your own code!\n\n\n\n\n\n\n\n\nNext: Go to Part 1.3: Survey adjusted plots"
  },
  {
    "objectID": "part1/part_1-2.html#footnotes",
    "href": "part1/part_1-2.html#footnotes",
    "title": "1.2: Survey adjusted descriptive statistics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is the name of our data.frame in our R environment. It is important that it contains the entire dataset from which the weights were calculated, not a subset where cases may be missing.↩︎"
  },
  {
    "objectID": "part2/part_2-1.html",
    "href": "part2/part_2-1.html",
    "title": "2.1: Regressions",
    "section": "",
    "text": "This sections covers: regression models and other advanced applications using European Social Survey data.\nIt also provides space to practice reading in a new dataset and survey design object.\nWelcome to the afternoon session!"
  },
  {
    "objectID": "part2/part_2-1.html#data-import",
    "href": "part2/part_2-1.html#data-import",
    "title": "2.1: Regressions",
    "section": "Data import",
    "text": "Data import\nWe will be importing the second dataset, the European Social Survey.\nThe data was downloaded as a .csv file, so we use the read_csv function from base R.\nRe-specify the “root” function if this value is no longer in your working directory. Remember to adjust this code to match the pathname to the folder where your workshop data is saved.\n\n\nCode\nroot &lt;- \"C://Users//s1769862//OneDrive - University of Edinburgh//SLTF-workshop-August2024//\" # change with where the folder lies in your filepath\n\n\nIf you downloaded the .csv file as a single folder from ESS without altering any file names or structure the data can be imported with this relative path and the root directory specified above.\n\n\nCode\ness9 &lt;- read.csv(file.path(root, \"ESS9e03_2\", \"ESS9e03_2.csv\"))\n\n\nNotice that variables from the .csv file imported as more typical classes, and do not have haven labelling like the .dta import.\n\n\nCode\nclass(ess9$cntry) # character for letter input\n\n\n[1] \"character\"\n\n\nCode\nclass(ess9$nwspol) # integer for numeric input\n\n\n[1] \"integer\"\n\n\nCode\nclass(ess9$ppltrst) # integer for numeric input\n\n\n[1] \"integer\""
  },
  {
    "objectID": "part2/part_2-1.html#data-cleaning",
    "href": "part2/part_2-1.html#data-cleaning",
    "title": "2.1: Regressions",
    "section": "Data cleaning",
    "text": "Data cleaning\nThe ESS data is very large and complex, so we will only clean a few variables to use in this example. The variety of the data also means we cannot apply a single logic for recoding all missing values, as was done with the Children’s Worlds Survey.\n\n\n\n\n\n\nCaution\n\n\n\nRemember to complete all cleaning and wrangling before setting the survey design object. However, do not restrict cases!\n\n\nWe will clean a few variables of interest.\n\nppltrst (“Most people can be trusted or you can’t be too careful”)\ntrstprl (“Trust in country’s parliament”)\nnwspol (Minutes spent consuming news)\nvote (“Voted in last election”)\ngndr (“Respondent gender”)\nagea (“Respondent age)\n\n\n\nCode\n# Missing transformation for ordinal variables\ness9$trstprl[ess9$trstprl&gt;10] &lt;- NA\n\n# cutoffs for continuous variables\ness9$nwspol[ess9$nwspol&gt;7000] &lt;- NA\ness9$agea[ess9$agea&gt;6000] &lt;- NA\n\n\n\n\nCode\ness9 &lt;- ess9 %&gt;%\n  dplyr::mutate(vote = as.factor(\n                  case_when(vote == 1 ~ \"Yes\",\n                            vote == 2 ~ \"No\",\n                            .default = NA)),\n                gender = as.factor(\n                  case_when(gndr == 1 ~ \"Male\",\n                            gndr == 2 ~ \"Female\",\n                            .default = NA)),\n                age = as.factor(\n                  case_when(agea &gt;17 & agea &lt;26 ~ \"18 to 25\",\n                            agea &gt;25 & agea &lt;36 ~ \"25 to 35\",\n                            agea &gt;35 & agea &lt;50 ~ \"36 to 49\",\n                            agea &gt;49 & agea &lt;65 ~ \"50 to 64\",\n                            agea &gt;64 & agea &lt;115 ~ \"65+\",\n                            agea &lt;18 | agea &gt;115 ~ NA)))"
  },
  {
    "objectID": "part2/part_2-1.html#sampling-design-object",
    "href": "part2/part_2-1.html#sampling-design-object",
    "title": "2.1: Regressions",
    "section": "Sampling design object",
    "text": "Sampling design object\nThe ESS makes our job easy and provides detailed guidance on setting the survey design object.\nAccording to the guide our survey design variables include:\n\nidsstrataweightsdata\n\n\npsu\nThe primary sampling unit, the smallest grouping where individual respondents are sampled from.\n\n\nstratum\nThe higher level stratification of the sampling design.\n\n\nanweight\nThe analysis weight, which is suitable for all analyses.\npspweight\nThe post-stratification weight, adjusting for non-response errors.\ndesign\nThe design weight, adjusting for the probability of selection into the sample.\n\n\ness9\nThe name of our data from in R working memory.\n\n\n\nThe documentation provides further detail about the weights because there are multiple that are available.\nAnalysis weight\n\n“Anweight corrects for differential selection probabilities within each country as specified by sample design, for nonresponse, for noncoverage, and for sampling error related to the four post-stratification variables, and takes into account differences in population size across countries. It is constructed by first deriving the design weight, then applying a post-stratification adjustment, and then a population size adjustment.”\n\nPost-stratification weight\n\n“While the design weights account for differences in inclusion probabilities, sampling errors (related to attempting to measure only a fraction of the population) and possible non-response errors (which may lead to a systematic over- or under-representation of people with certain characteristics) are still present. Post-stratification weights are a more sophisticated weighting strategy that uses auxiliary information to reduce the sampling error and potential non-response bias. They have been constructed using information on age group, gender, education, and region. The post-stratification weights are obtained by adjusting the design weights in such a way that they will replicate the distribution of the cross-classification of age group, gender, and education in the population and the marginal distribution for region in the population.”\n\nDesign weight\n\n“Several countries use complex sampling designs where some groups or regions of the population have higher probabilities of selection. The main purpose of the design weights is to correct for the fact that in some countries respondents have different probabilities to be part of the sample due to the sampling design used. Applying the weights allows for the construction of design unbiased estimators. The design weights are computed as the inverse of the inclusion probabilities, i.e. the probability of each person to be included into the sample. The inverse inclusion probabilities are then scaled such that their sum equals the net sample size and the mean equals one.”\n\nThe analysis weight anweight is a combination of the post-stratification weight pspweight and the population weight pweight. ESS weighting guidelines recommend using anweight for general analysis, so we will employ the recommended specification in the example today.\nCreate the survey design object.\n\n\nCode\ndesign2 &lt;- survey::svydesign(ids = ~psu, strata = ~stratum, weights = ~anweight, data = ess9)"
  },
  {
    "objectID": "part2/part_2-1.html#regression",
    "href": "part2/part_2-1.html#regression",
    "title": "2.1: Regressions",
    "section": "Regression",
    "text": "Regression\nNow we have the tools to dive into regression!\nThe survey package builds on the “General Linear Model” glm model framework, which underpins many popular regression functions in R. If you know the syntax for the glm you can apply pretty much any decisions to the svyglm function.\n\nThe glm function has several components:\n\nFunctionFamilyLinkData\n\n\nSpecify the relationship between our independent and dependent variables as a formula.\nFor example, outcome \\(y\\) with predictive variables \\(x_1\\), \\(x_2\\), or (\\(y = x_{1} + x_{2} + x_{3}\\))\nwould be expressed in the function as y ~ x1 + x2 + x3.\n\n\nThe family of distributions to apply to your formula.\nFor example, gaussian, quasi-binomial, binomial, or poisson.\n\n\nThe linking function for the algorithm that performs the regression calculation.\nFor example, identity, logit, or inverse. It does not need to be specified if defaults for the family are correct.\n\n\nThe name of your data frame in R working memory.\n\n\n\nFrom the user’s perspective, the primary difference between calling the svyglm() and regular glm() function is specifying the survey design object design= in place of the data frame data=. In our case, this means specifying design2 instead of ess9."
  },
  {
    "objectID": "part2/part_2-1.html#linear-regression",
    "href": "part2/part_2-1.html#linear-regression",
    "title": "2.1: Regressions",
    "section": "Linear regression",
    "text": "Linear regression\nLet’s try a simple ordinary least squares (OLS) linear regression.\nIs the amount of time one spends consuming news associated with how old they are?\nIf news consumption is \\(y\\) and age is \\(x\\) then our formula is simply nwspol ~ gender .\n\n\nCode\noptions(survey.lonely.psu=\"adjust\") # adjust for lonely psu\n\nsummary(survey::svyglm(nwspol ~ age, family=gaussian, design=design2))\n\n\n\nCall:\nsvyglm(formula = nwspol ~ age, design = design2, family = gaussian)\n\nSurvey design:\nsurvey::svydesign(ids = ~psu, strata = ~stratum, weights = ~anweight, \n    data = ess9)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   79.831      4.670  17.093  &lt; 2e-16 ***\nage25 to 35    5.072      5.561   0.912  0.36175    \nage36 to 49    3.880      5.066   0.766  0.44367    \nage50 to 64   17.284      5.511   3.136  0.00171 ** \nage65+        39.109      4.874   8.023 1.08e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 27434.39)\n\nNumber of Fisher Scoring iterations: 2\n\n\nIt appears that age has a significant association with new consumption. The time spent consuming news media is elevated for the highest age groups compared to the youngest.\nWe can also include tbl_regression() to make our model output more readable.\n\n\nCode\nsurvey::svyglm(nwspol ~ age, family=gaussian, design=design2) %&gt;%\n  gtsummary::tbl_regression() %&gt;%\n  modify_caption(\"Predicting time spent watching news\") %&gt;%\n  bold_p(t=0.05)\n\n\n\n\n\n\n  Predicting time spent watching news\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    age\n\n\n\n        18 to 25\n—\n—\n\n        25 to 35\n5.1\n-5.8, 16\n0.4\n        36 to 49\n3.9\n-6.0, 14\n0.4\n        50 to 64\n17\n6.5, 28\n0.002\n        65+\n39\n30, 49\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\nAdjusting for lonely primary sampling unit\nIf we run this code without the adjust for longely PSU we receive the following error message: Error in onestrat(attr&lt;-(x[index, , drop = FALSE], \"recentering\", recentering),  : Stratum (1680) has only one PSU at stage 1\nThis is quite a common error message. It means that there are not sufficient primary sampling units within a stratum, so standard calculations are failing.\nA commonly suggested solution is to allow the survey package to adjust for “lonely” PSUs. You can research all adjustment options and decide which is best for your use case.\n\n`options(survey.lonely.psu=“fail”)``options(survey.lonely.psu=“remove”)``options(survey.lonely.psu=“certainty”)``options(survey.lonely.psu=“adjust”)`\n\n\nThe default, which causes an error message and refuses to run the calculation.\n\n\nRemoves the single PSU so it has no contribution to variance calculations.\n\n\nAlso specifies that the single PS will have to contribution to variance\n\n\nCentres the single PSU at the sample grand mean rather than the stratum grand mean.\n\n\n\nWe will set options(survey.lonely.psu=\"adjust\") which is suggested as good choice when the problem is believe to be caused by random missingness, rather than an issue with the sampling design."
  },
  {
    "objectID": "part2/part_2-1.html#binary-logistic-regression",
    "href": "part2/part_2-1.html#binary-logistic-regression",
    "title": "2.1: Regressions",
    "section": "Binary logistic regression",
    "text": "Binary logistic regression\nThe survey package can handle multiple types of linear regressions, including binary logistic regression.\nLet us investigate the probability of individuals having voted in their last national election, given their trust in political institutions.\n\n\n\n\n\n\nNote\n\n\n\nIncluding exponentiate = T provides the coefficient estimates in odds ratios.\n\n\n\n\nCode\noptions(survey.lonely.psu=\"adjust\") # adjust for lonely psu\n\nsurvey::svyglm(vote ~ trstprl, family= quasibinomial, design=design2) %&gt;% gtsummary::tbl_regression(exponentiate=T)\n\n\n\n\n\n\n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    trstprl\n1.15\n1.13, 1.17\n&lt;0.001\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nRemember that 0 refers to a state of maximum distrust and 10 signifies the highest state of trust. Therefore, these model results indicate that there is a positive relationship between increased trust in parliament and whether a respondent voted in their last national election.\nJust as with descriptive tables, we can adjust the regression summary table to include more details.\n\n\nCode\nsurvey::svyglm(vote ~ trstprl, family= quasibinomial, design=design2) %&gt;%\n  gtsummary::tbl_regression(exponentiate = T,\n                            label = c(trstprl~\"Trust in parliament\")) %&gt;%\n  bold_p(t=0.05) %&gt;%\n  modify_caption(\"Predicting the odds of having voted in the last national election\") %&gt;%\n  as_gt() %&gt;%\n  gt::tab_source_note(gt::md(\"Data source: European Social Survey, 2018\"))\n\n\n\n\n\n\n  Predicting the odds of having voted in the last national election\n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    Trust in parliament\n1.15\n1.13, 1.17\n&lt;0.001\n  \n  \n    \n      Data source: European Social Survey, 2018\n    \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nWe can alter the formula for our model we to add control variables to the binary logit.\n\n\nCode\nsurvey::svyglm(vote ~ trstprl + gender + age, family=quasibinomial, design = design2) %&gt;%\n  gtsummary::tbl_regression(exponentiate = T,\n                            label = c(trstprl~\"Trust in parliament\")) %&gt;%\n  bold_p(t=0.05) %&gt;%\n  modify_caption(\"Predicting the odds of having voted in the last national election with control variables\") %&gt;%\n  as_gt() %&gt;%\n  gt::tab_source_note(gt::md(\"Data source: European Social Survey, 2018\"))\n\n\n\n\n\n\n  Predicting the odds of having voted in the last national election with control variables\n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    Trust in parliament\n1.17\n1.15, 1.19\n&lt;0.001\n    gender\n\n\n\n        Female\n—\n—\n\n        Male\n1.04\n0.96, 1.12\n0.4\n    age\n\n\n\n        18 to 25\n—\n—\n\n        25 to 35\n1.43\n1.24, 1.66\n&lt;0.001\n        36 to 49\n2.06\n1.79, 2.37\n&lt;0.001\n        50 to 64\n3.01\n2.61, 3.47\n&lt;0.001\n        65+\n3.41\n2.95, 3.94\n&lt;0.001\n  \n  \n    \n      Data source: European Social Survey, 2018\n    \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nOur result remains significant, even when controlling for age and gender. We can also see that as age increase so does the odds of having voted in the last election."
  },
  {
    "objectID": "part2/part_2-1.html#investigating-the-influence-of-the-survey-adjustments",
    "href": "part2/part_2-1.html#investigating-the-influence-of-the-survey-adjustments",
    "title": "2.1: Regressions",
    "section": "Investigating the influence of the survey adjustments",
    "text": "Investigating the influence of the survey adjustments\nWhat would happen if we did not adjust for survey weighting?\nWe can run the same model and below with the base glm function and compare the results.\n\n\nCode\nglm(vote ~ trstprl + gender + age, family=quasibinomial, dat= ess9) %&gt;%\n  gtsummary::tbl_regression(exponentiate = T,\n                            label = c(trstprl~\"Trust in parliament\")) %&gt;%\n  bold_p(t=0.05) %&gt;%\n  modify_caption(\"Predicting the odds of having voted in the last national election with control variables\") %&gt;%\n  as_gt() %&gt;%\n  gt::tab_source_note(gt::md(\"Sampling adjustment *not* applied. Data source: European Social Survey, 2018\"))\n\n\n\n\n\n\n  Predicting the odds of having voted in the last national election with control variables\n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    Trust in parliament\n1.17\n1.16, 1.19\n&lt;0.001\n    gender\n\n\n\n        Female\n—\n—\n\n        Male\n1.06\n1.01, 1.12\n0.010\n    age\n\n\n\n        18 to 25\n—\n—\n\n        25 to 35\n1.71\n1.55, 1.88\n&lt;0.001\n        36 to 49\n2.38\n2.18, 2.60\n&lt;0.001\n        50 to 64\n3.32\n3.03, 3.62\n&lt;0.001\n        65+\n3.91\n3.58, 4.28\n&lt;0.001\n  \n  \n    \n      Sampling adjustment not applied. Data source: European Social Survey, 2018\n    \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nStrikingly, the effect of gender on voting behaviour becomes significant when the sampling design is not accounted for. This indicates that we would erroneously report a relationship that is not robust if tools for complex samples were not utilised."
  },
  {
    "objectID": "part2/part_2-1.html#task-8",
    "href": "part2/part_2-1.html#task-8",
    "title": "2.1: Regressions",
    "section": "Task 8",
    "text": "Task 8\nConstruct your own regression analysis and display the results in a gtsummary table!\n\n\n\n\n\n\nTip\n\n\n\nRemember to convert any missing values to NA and ensure that your columns are the correct class for your analysis. If you make any changes to the original data frame in your data cleaning, remember to specify a new survey design object with the updated data frame.\n\n\n\n\nCode\n## Write your own code!\n\n## hint: copy and past code from previous chunks"
  },
  {
    "objectID": "part2/part_2-1.html#interaction-effects",
    "href": "part2/part_2-1.html#interaction-effects",
    "title": "2.1: Regressions",
    "section": "Interaction effects",
    "text": "Interaction effects\nWe can also specify interaction effects by modifying the regression formula. For example, I may wonder if trust in politics has a different influence on past voting behaviour by gender.\n\n\nCode\nsurvey::svyglm(vote ~ trstprl*age + gender, family=quasibinomial, design = design2) %&gt;%\n  gtsummary::tbl_regression(exponentiate = T,\n                            label = c(trstprl~\"Trust in parliament\")) %&gt;%\n  bold_p(t=0.05) %&gt;%\n  modify_caption(\"Predicting the odds of having voted in the last national election with interaction effects\") %&gt;%\n  as_gt() %&gt;%\n  gt::tab_source_note(gt::md(\"Data source: European Social Survey, 2018\"))\n\n\n\n\n\n\n  Predicting the odds of having voted in the last national election with interaction effects\n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    Trust in parliament\n1.17\n1.12, 1.23\n&lt;0.001\n    age\n\n\n\n        18 to 25\n—\n—\n\n        25 to 35\n1.58\n1.18, 2.13\n0.002\n        36 to 49\n2.00\n1.50, 2.65\n&lt;0.001\n        50 to 64\n2.86\n2.13, 3.86\n&lt;0.001\n        65+\n3.39\n2.53, 4.56\n&lt;0.001\n    gender\n\n\n\n        Female\n—\n—\n\n        Male\n1.03\n0.96, 1.12\n0.4\n    Trust in parliament * age\n\n\n\n        Trust in parliament * 25 to 35\n0.98\n0.92, 1.03\n0.4\n        Trust in parliament * 36 to 49\n1.01\n0.95, 1.07\n0.8\n        Trust in parliament * 50 to 64\n1.01\n0.96, 1.07\n0.7\n        Trust in parliament * 65+\n1.00\n0.94, 1.06\n&gt;0.9\n  \n  \n    \n      Data source: European Social Survey, 2018\n    \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nLooks like my theory was not supported by the data. Although trust in politicians and age both have main effects on voting, there is not evidence of a significant interaction effect."
  },
  {
    "objectID": "part2/part_2-1.html#save-data",
    "href": "part2/part_2-1.html#save-data",
    "title": "2.1: Regressions",
    "section": "Save data",
    "text": "Save data\nTo transport our analysis to the final session we can save it as an RData file to the workshop folder.\n\n\nCode\nsaveRDS(ess9, file = file.path(root, \"Data\", \"ess9.RData\"))\n\n\n\n\n\n\n\n\nNext: Go to Part 2.2: Extensions"
  }
]